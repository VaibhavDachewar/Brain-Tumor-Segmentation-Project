\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\title{Hardware-Software Co-Design for Brain Tumor Segmentation Using U-Net Architecture}

\author{
    \IEEEauthorblockN{Abu Huzaifa, Vaibhav Naresh Dachewar, Prof. Rituparna Choudhury}
    \IEEEauthorblockA{\textit{Dept. of Electronics and Communication Engineering} \\
    \textit{International Institute of Information Technology Bangalore}\\
    Bangalore, India \\
    abu.huzaifa@iiitb.ac.in, vaibhavnaresh.dachewar@iiitb.ac.in, rituparna.choudhury@iiitb.ac.in}
}

\begin{document}

\maketitle

\begin{abstract}
This paper presents a Hardware-Software Co-Design methodology for brain tumor segmentation using the U-Net architecture. The software part involves training and testing the U-Net on 3064 T1-weighted contrast-enhanced MRI images, achieving significant segmentation performance. The hardware part implements modular Verilog designs for each U-Net block, allowing FPGA-based acceleration. Module-wise synthesis results are reported for individual Verilog modules, paving the way for full U-Net deployment on FPGA.
\end{abstract}

\begin{IEEEkeywords}
U-Net, Brain Tumor Segmentation, Hardware-Software Co-Design, FPGA, Verilog, MRI, Deep Learning
\end{IEEEkeywords}

\section{Introduction}
Brain tumor segmentation in MRI images is critical for clinical diagnosis and treatment planning. Manual segmentation is time-consuming and prone to human error. With advances in deep learning, architectures like U-Net have demonstrated excellent performance in biomedical image segmentation \cite{b2}. This work explores a hardware-software co-design methodology: software training of U-Net for segmentation, followed by hardware implementation of modular Verilog blocks for FPGA acceleration.

\section{Related Work}
Several studies integrate deep learning with FPGA acceleration for medical imaging. Díaz-Pernas et al. \cite{b3} proposed a multiscale CNN for tumor detection. Mallick et al. \cite{b7} used CNNs (EfficientNetB0, VGG16) with FPGA for classification. Popat et al. \cite{b8} introduced Box-U-Net, improving segmentation accuracy. Rayapati et al. \cite{b5} implemented Otsu and Watershed algorithms on FPGA, achieving real-time performance. Chatterjee et al. \cite{b6} designed custom IP cores for edge detection. These studies motivated our modular Verilog implementation.

\section{Dataset and Preprocessing}
The dataset consists of 3064 T1-weighted contrast-enhanced MRI images from 233 patients: meningioma (708), glioma (1426), and pituitary tumors (930) \cite{b1}. Preprocessing included resizing images to $256\times256$ and normalizing pixel intensities. Each image-mask pair was used for supervised training.

\section{Software Design and Training}
\subsection{U-Net Architecture}
The U-Net consists of an encoder-decoder structure with skip connections. Each encoder block includes two Conv2D-BatchNorm-ReLU layers followed by MaxPooling, while decoder blocks use Conv2DTranspose layers.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{unet_block_diagram.png} % You can redraw this from your code
    \caption{U-Net Block Diagram}
    \label{fig:unet_block}
\end{figure}

\subsection{Implementation}
Python scripts (`unet.py`, `metric.py`, `train.py`, `test.py`) were executed on Google Colab using GPU acceleration. The model was trained for 50 epochs (runtime: 91.5 minutes) with initial learning rate $10^{-4}$ decayed progressively.

\begin{table}[H]
\caption{Training Details}
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Parameter}       & \textbf{Value}           \\ \hline
Epochs                   & 50                       \\ \hline
Batch Size               & 8                        \\ \hline
Optimizer                 & Adam                     \\ \hline
Learning Rate            & $10^{-4}$ (decayed)      \\ \hline
Runtime                  & 91.5 minutes             \\ \hline
\end{tabular}
\label{tab:training_details}
\end{table}

\subsection{Performance Metrics}
After testing, the model achieved:
\begin{itemize}
    \item Dice Coefficient: 0.8176
    \item Jaccard Index: 0.6710
    \item F1 Score: 0.7527
    \item Precision: 0.7955
    \item Recall: 0.7624
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{segmentation_results.png} % Replace with actual image
    \caption{Sample Segmentation Output: (a) Input MRI, (b) Ground Truth, (c) Predicted Mask}
    \label{fig:segmentation}
\end{figure}

\section{Hardware Design}
\subsection{Modular Verilog Implementation}
The U-Net architecture was decomposed into the following Verilog modules:
\begin{itemize}
    \item \texttt{conv2d\_layer.v}
    \item \texttt{batchnorm\_relu.v}
    \item \texttt{maxpool2d.v}
    \item \texttt{conv2d\_transpose.v}
    \item \texttt{encoder\_block.v}, \texttt{decoder\_block.v}
    \item \texttt{feature\_concatenate.v}
    \item Top-level: \texttt{unet\_top.v}
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{fpga_hierarchy.png} % Redraw based on your folder hierarchy
    \caption{Hierarchical Hardware Design}
    \label{fig:fpga_hierarchy}
\end{figure}

\subsection{Dataflow Diagram}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{dataflow_diagram.png} % Refer Rayapati et al. Fig.2 as base
    \caption{Dataflow between U-Net Modules in FPGA}
    \label{fig:dataflow}
\end{figure}

\section{Hardware Results}
Each Verilog module was simulated and synthesized independently using Vivado.

\begin{table}[H]
\caption{Module-wise Hardware Synthesis Results (to be filled)}
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Module              & LUTs Used & FFs Used & Max Freq (MHz) \\ \hline
Conv2D Layer        &           &          &               \\ \hline
BatchNorm+ReLU      &           &          &               \\ \hline
MaxPooling          &           &          &               \\ \hline
Conv2DTranspose     &           &          &               \\ \hline
Encoder Block        &           &          &               \\ \hline
Decoder Block        &           &          &               \\ \hline
Feature Concatenate &           &          &               \\ \hline
\end{tabular}
\label{tab:hardware_results}
\end{table}

\section{Conclusion}
This work successfully demonstrates a hardware-software co-design methodology for brain tumor segmentation. Future work includes optimizing memory usage and integrating the complete U-Net on FPGA.

\section*{References}
\begin{thebibliography}{00}
\bibitem{b1} Cheng J., et al., “Enhanced Performance of Brain Tumor Classification via Tumor Region Augmentation,” PLoS ONE, 2015.
\bibitem{b2} Ronneberger O., et al., “U-Net: Convolutional Networks for Biomedical Image Segmentation,” MICCAI, 2015.
\bibitem{b3} Bhanothu Y., et al., “Detection and Classification of Brain Tumor using Deep CNN,” ICACCS, 2020.
\bibitem{b4} Khalil A., et al., “Hardware Acceleration of U-Net on FPGA,” IEEE, 2019.
\bibitem{b5} Rayapati H., et al., “FPGA Co-design for Brain Tumor Segmentation,” IEEE, 2021.
\bibitem{b6} Chatterjee S., et al., “FPGA Custom IP Core for Edge Detection,” VDAT, 2024.
\bibitem{b7} Mallick A., et al., “Deep Learning for Brain Tumor Detection with FPGA Pathway,” iSES, 2024.
\bibitem{b8} Popat M., et al., “Brain Tumor Segmentation using Box-U-Net,” ICAEECI, 2023.
\end{thebibliography}

\end{document}
